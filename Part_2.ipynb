{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load snaowball Stemmer\n",
    "sbEsp = SnowballStemmer('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(scentence):\n",
    "    #We only want to work with lowercase for the comparisons\n",
    "    scentence = scentence.lower()\n",
    "\n",
    "    #remove punctuation and split into seperate words\n",
    "    words = re.findall(r'\\w+', scentence,flags = re.UNICODE)\n",
    "    return ' '.join([sbEsp.stem(item) for item in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('reviews.json', encoding = 'utf-8') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 read the needed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for paper in data['paper']:\n",
    "    for review in paper['review']:\n",
    "        if review['lan'] == 'es' and review['text']:\n",
    "            # preprocessing the text\n",
    "            text = preprocessing(review['text'])\n",
    "            dataset.append([review['evaluation'], text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(dataset, columns=[\"evaluation\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evaluation</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>el articul abord un problem contingent y muy r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>el articul present recomend practic par el des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>el tem es muy interes y pued ser de much ayud ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>se explic en form orden y didact una experient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>los autor describ una metodolog par desarroll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>este trabaj propon un nuev enfoqu bas en 25 pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>se realiz un trabaj de model de encript cuanti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2</td>\n",
       "      <td>este pap involucr el desarroll de una aplic qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>noved propuest bien estructur correct escrit s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>el tem es interes y esta bien estructur en lo ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  evaluation                                               text\n",
       "0          1  el articul abord un problem contingent y muy r...\n",
       "1          1  el articul present recomend practic par el des...\n",
       "2          1  el tem es muy interes y pued ser de much ayud ...\n",
       "3          2  se explic en form orden y didact una experient...\n",
       "4          2  los autor describ una metodolog par desarroll ...\n",
       "5          2  este trabaj propon un nuev enfoqu bas en 25 pa...\n",
       "6          2  se realiz un trabaj de model de encript cuanti...\n",
       "7         -2  este pap involucr el desarroll de una aplic qu...\n",
       "8          2  noved propuest bien estructur correct escrit s...\n",
       "9          2  el tem es interes y esta bien estructur en lo ..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Convert the text to numerical data using Unigram bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stopwords)\n",
    "vectorized = vectorizer.fit_transform(dataframe['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorized.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       2\n",
       "4       2\n",
       "       ..\n",
       "377    -1\n",
       "378    -1\n",
       "379    -1\n",
       "380     1\n",
       "381     1\n",
       "Name: evaluation, Length: 382, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataframe.evaluation\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 split the dataset into Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training the LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Test data is : 77\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of Test data is : {}\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Review</th>\n",
       "      <th>Predicted Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>-2</td>\n",
       "      <td>-4.366314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1</td>\n",
       "      <td>0.332616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.657565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>-2</td>\n",
       "      <td>-2.982346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2</td>\n",
       "      <td>0.687870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1</td>\n",
       "      <td>0.692250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>-1</td>\n",
       "      <td>-0.946365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0</td>\n",
       "      <td>0.849922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>0.760405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1.599318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual Review  Predicted Review\n",
       "281            -2         -4.366314\n",
       "122             1          0.332616\n",
       "353             1         -0.657565\n",
       "324            -2         -2.982346\n",
       "173             2          0.687870\n",
       "..            ...               ...\n",
       "238             1          0.692250\n",
       "240            -1         -0.946365\n",
       "235             0          0.849922\n",
       "56              0          0.760405\n",
       "8               2          1.599318\n",
       "\n",
       "[77 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression predicts the evaluation value from the test set\n",
    "# actual column is the same as evaluation column in Dataset\n",
    "df = pd.DataFrame({'Actual Review': y_test, 'Predicted Review': y_pred})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Evaluating the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.2950624128928987\n",
      "Mean Squared Error: 3.3903031130826737\n",
      "Root Mean Squared Error: 1.8412775763264684\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Give the most important 10 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Display the most important 10 features for positive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most important 10 features for positive review:\n",
      "\n",
      "Feature : gust \t, Importance : 0.42371618721324383\n",
      "Feature : clarid \t, Importance : 0.3702371131821889\n",
      "Feature : buen \t, Importance : 0.3568649684556298\n",
      "Feature : motiv \t, Importance : 0.33958112423873155\n",
      "Feature : previ \t, Importance : 0.334299071646675\n",
      "Feature : mostr \t, Importance : 0.31266237188409446\n",
      "Feature : actual \t, Importance : 0.3100917070215693\n",
      "Feature : adjunt \t, Importance : 0.3094197399507518\n",
      "Feature : tal \t, Importance : 0.30760950003073095\n",
      "Feature : caracterist \t, Importance : 0.2899963351039534\n"
     ]
    }
   ],
   "source": [
    "print(\"The most important 10 features for positive review:\\n\")\n",
    "for i in (regressor.coef_).argsort()[::-1][:10]:\n",
    "    print(\"Feature : {} \\t, Importance : {}\".format(feature_names[i], np.abs(regressor.coef_[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Display the most important 10 features for negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most important 10 features for negative review\n",
      "\n",
      "Feature : nul \t, Importance : 0.6786741705609403\n",
      "Feature : exist \t, Importance : 0.5753291642011342\n",
      "Feature : cientif \t, Importance : 0.5743425043181307\n",
      "Feature : aport \t, Importance : 0.5113338865125555\n",
      "Feature : sid \t, Importance : 0.44225134472246863\n",
      "Feature : solucion \t, Importance : 0.4160958260530073\n",
      "Feature : explicit \t, Importance : 0.4107089714098794\n",
      "Feature : format \t, Importance : 0.38188972616656713\n",
      "Feature : investig \t, Importance : 0.3779468566636736\n",
      "Feature : mal \t, Importance : 0.3622090953003124\n"
     ]
    }
   ],
   "source": [
    "print(\"The most important 10 features for negative review:\\n\")\n",
    "for i in (-regressor.coef_).argsort()[::-1][:10]:\n",
    "    print(\"Feature : {} \\t, Importance : {}\".format(feature_names[i], np.abs(regressor.coef_[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
